{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# TESScut and ExoMAST: Working with TESS Time Series Data\n",
    "\n",
    "In this tutorial we will learn about MAST's programmatic tools for accessing TESS time series data while exploring a \"weird looking\" light curve.  We will follow up on unusual TCE results using the MAST API in Python to access and view TESS time series and FFI data.\n",
    "\n",
    "Topics to be covered include:\n",
    "- Using the MAST API to get data validation time series\n",
    "- Plotting TESS light curves in Python\n",
    "- Using the MAST API to make an FFI cutout\n",
    "- Creating a movie of TPF frames in Python\n",
    "\n",
    "See the __[MAST TESS site](http://archive.stsci.edu/tess/)__ for more information and example on how to access and use TESS data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "- **TESS:** The Transiting Exoplanet Survey Satellite\n",
    "- **Sector:** TESS observed the sky in regions of 24x96 degrees along the southern, then northern, ecliptic hemispheres. Each of these regions is referred to as a \"sector\", starting with Sector 1.\n",
    "- **TCE:** Threshold Crossing Event, periodic signals found by the TESS pipeline that exceed a nominal signal-to-noise ratio.\n",
    "- **Data Validation (DV):** The Data Validation (DV) module of the pipeline produces a set of products that can help validate the quality of a TCE. The DV products include a time series file of the flattened light curve that was searched and relevant statistics for each signal (dvt.fits), DV reports that consists of a few diagnostic plots and relevant statistics (dvs.pdf for individual signals, dvr.pdf for all signals found in the TIC object), and an xml file (dvr.xml) that contains the results of the planet transit fit. We will be exploring a dvt.fits file in this tutorial.\n",
    "- **FFI:** TESS periodically reads out the entire frame of all four cameras, nominally every 30 minutes, and stores them as full frame images (FFIs). \n",
    "- **HDU:** Header Data Unit. A FITS file is made up of HDUs that contain data and metadata relating to the file. The first HDU is called the primary HDU, and anything that follows is considered an \"extension\", e.g., \"the first FITS extension\", \"the second FITS extension\", etc.\n",
    "- **HDUList:** A list of HDUs that comprise a fits file.\n",
    "- **BJD:** Barycentric Julian Date, the Julian Date that has been corrected for differences in the Earth's position with respect to the Solar System center of mass.\n",
    "- **BTJD:** Barycentric TESS Julian Date, the timestamp measured in BJD, but offset by 2457000.0. I.e., BTJD = BJD - 2457000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use a HTTP based web service API, as well as Astroquery to find and download data.\n",
    "\n",
    "We will use both the matplotlib and bokeh packages to visualize our data as they have different strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# For querying for data\n",
    "import requests\n",
    "from astroquery.mast import Tesscut\n",
    "\n",
    "# For manipulating data\n",
    "import numpy as np\n",
    "\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import re\n",
    "\n",
    "# For matplotlib plotting\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# For animation display\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "# For bokeh plotting\n",
    "from bokeh import plotting\n",
    "plotting.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "There is something weird in the lightcurve of a particular TESS object, we want to find out what is causing the weirdness.  We know the TIC ID of the object in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_tic_id = \"00214568914\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using requests to query ExoMAST\n",
    "\n",
    "__[ExoMAST](https://exo.mast.stsci.edu)__ is MAST's exoplanet specific interface.  We can access its functionality programmatically by using its __[HTTP based API](https://exo.mast.stsci.edu/docs/)__.\n",
    "\n",
    "The main ExoMAST API url is `https://exo.mast.stsci.edu/api/v0.1/`.\n",
    "We will use several queries in this tutorial:\n",
    "- Find TCEs associated with a given TIC ID: `dvdata/tess/<TIC ID>/tces/`\n",
    "- Get DV metadata associated with a particular TCE: `dvdata/tess/<TIC ID>/info/?tce=<TCE>`\n",
    "- Get the DV time series associated with a particular TCE: `dvdata/tess/<TIC ID>/table/?tce=<TCE>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exomast_url = \"https://exo.mast.stsci.edu/api/v0.1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing the TCEs associated with our TIC ID\n",
    "\n",
    "To do this we build the query url and then perform an HTTP GET using the `requests` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tce_query = f\"{exomast_url}dvdata/tess/{weird_tic_id}/tces/\"\n",
    "list_tce_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(list_tce_query)\n",
    "tce_dict = response.json()\n",
    "print(tce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_tce = tce_dict['TCE'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the meta data associated with our TCE\n",
    "To do this we build the metadata query url and then perform another HTTP GET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_metadata_query = f\"{exomast_url}dvdata/tess/{weird_tic_id}/info/?tce={weird_tce}\"\n",
    "dv_metadata_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(dv_metadata_query)\n",
    "metadata = response.json()\n",
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['DV Primary Header'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['DV Data Header'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the DV data time series associated with our TCE\n",
    "\n",
    "This time we build a data table query url and then perform the HTTP GET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_lightcurve_query = f\"{exomast_url}dvdata/tess/{weird_tic_id}/table/?tce={weird_tce}\"\n",
    "dv_lightcurve_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(dv_lightcurve_query)\n",
    "data_dict = response.json()\n",
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_dict['fields']:\n",
    "    print(f\"{col['colname']} {col['datatype']:5} {col['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning our JSON data into an Astropy Table\n",
    "\n",
    "This step is not strictly necessary, we could certainly use our data directly in its current form, however, it is often convenient to put it in a data table.  Here we will use a function to put our results into an Astropy table, but you could similarly fill a Pandas table or numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_table(fields, data):\n",
    "    \"\"\"\"\n",
    "    Takes a json object and turns it into an astropy table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fields : list of dicts\n",
    "        Of the form [{colname:,datatype:,description:}, ...]\n",
    "    data : list of dicts\n",
    "       Of the form [{col1:, col2:, ...},{col1:, col2:, ...}, ...]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    response : `astropy.table.Table`\n",
    "    \"\"\"\n",
    "\n",
    "    rx = re.compile(r\"varchar\\((\\d+)\\)\")\n",
    "    \n",
    "    data_table = Table()\n",
    "\n",
    "    for col, atype in [(x['colname'], x['datatype']) for x in fields]:\n",
    "        col = col.strip()\n",
    "        if \"varchar\" in atype:\n",
    "            match = rx.search(atype)\n",
    "            atype = \"U\" + match.group(1)\n",
    "        if atype == \"real\":\n",
    "            atype = \"float\"\n",
    "        data_table[col] = np.array([x.get(col, None) for x in data], dtype=atype)\n",
    "\n",
    "    return data_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_lightcurve = json_to_table(data_dict['fields'],data_dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_lightcurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our light curve\n",
    "\n",
    "We will start by using `matplotlib` to quickly plot up the detrended light curve by phase, which will allow us to observe TCE signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,4))\n",
    "\n",
    "# plotting the phased light curve\n",
    "ax.plot(weird_lightcurve[\"PHASE\"], weird_lightcurve['LC_DETREND'], \n",
    "        marker='.',linestyle='None', markersize=1, markerfacecolor='black', markeredgecolor=\"black\") \n",
    "    \n",
    "plt.title(f\"Detrended Lightcurve (TIC{weird_tic_id}-{weird_tce})\")            \n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is definitely *something* happening in that light curve.  We will now use `bokeh` so we can zoom in on the anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfig = plotting.figure(plot_width=850, plot_height=250, title=f\"Detrended Lightcurve (TIC{weird_tic_id})\")\n",
    "bfig.circle(weird_lightcurve[\"PHASE\"],weird_lightcurve[\"LC_DETREND\"], fill_color=\"black\",size=1, line_color=None)\n",
    "plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an FFI cutout\n",
    "\n",
    "We want to see what is going on with this light curve, so we will make a cutout around the object accross the entire sectore, and then make a movie that shows how it changes over time.\n",
    "\n",
    "We will use the `astroquery.mast` __[Tesscut](https://astroquery.readthedocs.io/en/latest/mast/mast.html#tesscut)__ class to make this cutout.  \n",
    "We will use two functions:\n",
    "- Find the sectors in which our object was observed: `Tesscut.get_sectors`\n",
    "- Query for cutouts and get the result as a list of HDUList objects: `Tesscut.get_cutouts`\n",
    "\n",
    "These queries require us to know the RA and Dec of our object of interest, which was in the metadata we queried earlier in the tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = metadata['DV Data Header']['RA_OBJ']\n",
    "dec = metadata['DV Data Header']['DEC_OBJ']\n",
    "obj_coord = SkyCoord(ra,dec,unit=\"deg\")\n",
    "print(obj_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting a list of TESS sectors that observed our target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesscut.get_sectors(obj_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requesting a cutout target pixel file.**\n",
    "\n",
    "This query will return a list of `HDUList` objects, each of which is the cutout target pixel file for a single sector. In this case, because we did a sector query and know that our target only appears in one sector, we know that the resulting list will only have one element and can pull it out directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_hdu = Tesscut.get_cutouts(obj_coord, size=50)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cutout_table = cutout_hdu[1].data\n",
    "cutout_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the cutout time series\n",
    "\n",
    "We want to explore what is happening with in our cutout area over time, so we will make an animated plot of the cutout frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding which timeframe to look at\n",
    "\n",
    "We can't make a movie of the whole sector (it would take too long), so we will look at the light curve to see where we think the weirdness happens.\n",
    "\n",
    "This time instead of plotting the phased light curve, we will just plot the detrended lightcurve against time (in BTJD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfig = plotting.figure(plot_width=850, plot_height=250, title=f\"Detrended Lightcurve (TIC{weird_tic_id})\")\n",
    "bfig.circle(weird_lightcurve[\"TIME\"],weird_lightcurve[\"LC_DETREND\"], fill_color=\"black\",size=1, line_color=None)\n",
    "plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see which parts we want to explore in more depth, we just need to figure out which frames of the cutout array correspond to the timestamps in our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(btjd):\n",
    "    \"\"\"\n",
    "    Given a time as a Barycentric TESS Julian Date (BTJD) timestamp, return the closest index in a table\n",
    "    that is assumed to have a TIME column that is also in BTJD\"\"\"\n",
    "    \n",
    "    return (np.abs(cutout_table['TIME'] - btjd)).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = find_index(1334)\n",
    "end = find_index(1335)\n",
    "\n",
    "print(f\"Frames {start}-{end} ({end-start} frames)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the animated cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_animation(data_array, start_frame=0, end_frame=None, vmin=None, vmax=None, delay=50):\n",
    "    \"\"\"\n",
    "    Function that takes an array where each frame is a 2D image array and make an animated plot\n",
    "    that runs through the frames.\n",
    "    \n",
    "    Note: This can take a long time to run if you have a lot of frames.    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_array : array\n",
    "        Array of 2D images.\n",
    "    start_frame : int\n",
    "        The index of the initial frame to show. Default is the first frame.\n",
    "    end_frame : int\n",
    "        The index of the final frame to show. Default is the last frame.\n",
    "    vmin : float\n",
    "        Data range min for the colormap. Defaults to data minimum value.\n",
    "    vmax : float\n",
    "        Data range max for the colormap. Defaults to data maximum value.\n",
    "    delay: \n",
    "        Delay before the next frame is shown in milliseconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    response : `animation.FuncAnimation`\n",
    "    \"\"\"\n",
    "    \n",
    "    if not vmin:\n",
    "        vmin = np.min(data_array)\n",
    "    if not vmax:\n",
    "        vmax = np.max(data_array)\n",
    "        \n",
    "    if not end_frame:\n",
    "        end_frame = len(data_array) - 1 # set to the end of the array\n",
    "        \n",
    "    num_frames = end_frame - start_frame + 1 # include the end frame\n",
    "        \n",
    "    def animate(i, fig, ax, binarytab, start=0):\n",
    "        \"\"\"Function used to update the animation\"\"\"\n",
    "        ax.set_title(\"Epoch #\" + str(i+start))\n",
    "        im = ax.imshow(binarytab[i+start], cmap=plt.cm.YlGnBu_r, vmin=vmin, vmax=vmax)\n",
    "        return im,\n",
    "    \n",
    "    # Create initial plot.\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.imshow(data_array[start_frame], cmap=plt.cm.YlGnBu_r, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, fargs=(fig, ax, data_array, start_frame), frames=num_frames, \n",
    "                                  interval=delay, repeat_delay=1000)\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_animation(cutout_table['FLUX'], start, end, vmax=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
